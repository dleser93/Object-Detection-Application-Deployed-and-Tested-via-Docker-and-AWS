{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVN0ypfiTA1Y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For downloading the image.\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "from six.moves.urllib.request import urlopen\n",
    "import io\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import numpy as np\n",
    "\n",
    "# For running inference on the TF-Hub module.\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# For measuring the inference time.\n",
    "import time\n",
    "\n",
    "from PIL import ImageColor\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check available GPU devices.\n",
    "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxUHHkkOTcDu"
   },
   "source": [
    "# Download Example Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cz9ShVMgTWgD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image)\n",
    "\n",
    "def display_image_from_base64(image_data):\n",
    "    imgdata = base64.b64decode(image_data)\n",
    "    image = Image.open(BytesIO(imgdata))\n",
    "    display_image(image)\n",
    "    \n",
    "    \n",
    "def download_and_resize_image(url, new_width=256, new_height=256,\n",
    "                              display=False):\n",
    "    _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
    "    response = urlopen(url)\n",
    "    image_data = response.read()\n",
    "    image_data = BytesIO(image_data)\n",
    "    pil_image = Image.open(image_data)\n",
    "    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
    "    pil_image_rgb = pil_image.convert(\"RGB\")\n",
    "    pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
    "    print(\"Image downloaded to %s.\" % filename)\n",
    "    if display:\n",
    "        display_image(pil_image)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ax4jEqfWTOz-",
    "outputId": "4cc59561-b55c-40a8-ddc4-6016d1279bfa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# By Heiko Gorski, Source: https://commons.wikimedia.org/wiki/File:Naxos_Taverna.jpg\n",
    "#image_url = \"https://upload.wikimedia.org/wikipedia/commons/6/60/Naxos_Taverna.jpg\"  #@param\n",
    "\n",
    "#downloaded_image_path = download_and_resize_image(image_url, 1280, 856, True)\n",
    "\n",
    "image_urls = [\n",
    "  # Source: https://commons.wikimedia.org/wiki/File:The_Coleoptera_of_the_British_islands_(Plate_125)_(8592917784).jpg\n",
    "  \"https://upload.wikimedia.org/wikipedia/commons/1/1b/The_Coleoptera_of_the_British_islands_%28Plate_125%29_%288592917784%29.jpg\",\n",
    "  # By AmÃ©rico Toledano, Source: https://commons.wikimedia.org/wiki/File:Biblioteca_Maim%C3%B3nides,_Campus_Universitario_de_Rabanales_007.jpg\n",
    "  \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg/1024px-Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg\",\n",
    "  # Source: https://commons.wikimedia.org/wiki/File:The_smaller_British_birds_(8053836633).jpg\n",
    "  \"https://upload.wikimedia.org/wikipedia/commons/0/09/The_smaller_British_birds_%288053836633%29.jpg\",\n",
    "]\n",
    "\n",
    "img_list = []\n",
    "for image_url in image_urls:\n",
    "    img_list.append(download_and_resize_image(image_url, 1280, 856, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLGKwDYcUGK9"
   },
   "source": [
    "# Transform Images to String:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbqsfSkUUJtM",
    "outputId": "0ba58c07-5c88-41ad-8a58-acb421a1ab97",
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for item in img_list:\n",
    "    with open(item, \"rb\") as img_file:\n",
    "        images.append(base64.b64encode(img_file.read()))\n",
    "        \n",
    "print(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color,\n",
    "                               font,\n",
    "                               thickness=4,\n",
    "                               display_str_list=()):\n",
    "    \"\"\"Adds a bounding box to an image.\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    im_width, im_height = image.size\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                ymin * im_height, ymax * im_height)\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "             (left, top)],\n",
    "            width=thickness,\n",
    "            fill=color)\n",
    "\n",
    "    # If the total height of the display strings added to the top of the bounding\n",
    "    # box exceeds the top of the image, stack the strings below the bounding box\n",
    "    # instead of above.\n",
    "    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "    # Each display_str has a top and bottom margin of 0.05x.\n",
    "    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "    if top > total_display_str_height:\n",
    "        text_bottom = top\n",
    "    else:\n",
    "        text_bottom = top + total_display_str_height\n",
    "    # Reverse list and print from bottom to top.\n",
    "    for display_str in display_str_list[::-1]:\n",
    "        text_width, text_height = font.getsize(display_str)\n",
    "        margin = np.ceil(0.05 * text_height)\n",
    "        draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
    "                    (left + text_width, text_bottom)],\n",
    "                   fill=color)\n",
    "        draw.text((left + margin, text_bottom - text_height - margin),\n",
    "              display_str,\n",
    "              fill=\"black\",\n",
    "              font=font)\n",
    "        text_bottom -= text_height - 2 * margin\n",
    "\n",
    "\n",
    "\n",
    "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n",
    "    \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
    "    colors = list(ImageColor.colormap.values())\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n",
    "                              25)\n",
    "    except IOError:\n",
    "        print(\"Font not found, using default font.\")\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for i in range(min(boxes.shape[0], max_boxes)):\n",
    "        if scores[i] >= min_score:\n",
    "            ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "            display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n",
    "                                         int(100 * scores[i]))\n",
    "            color = colors[hash(class_names[i]) % len(colors)]\n",
    "            image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
    "            draw_bounding_box_on_image(\n",
    "              image_pil,\n",
    "              ymin,\n",
    "              xmin,\n",
    "              ymax,\n",
    "              xmax,\n",
    "              color,\n",
    "              font,\n",
    "              display_str_list=[display_str])\n",
    "            np.copyto(image, np.array(image_pil))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_base64_to_input_format(image_data):\n",
    "    imgdata = base64.b64decode(image_data)\n",
    "    image = Image.open(BytesIO(imgdata))\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape((1, im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def input_format_to_image_base64(input_image):\n",
    "    image = Image.fromarray( np.asarray(input_image))\n",
    "    with BytesIO() as buffer:\n",
    "        image.save(buffer, format=\"PNG\")\n",
    "        image_data = buffer.getvalue()\n",
    "    image_base64 = base64.b64encode(image_data).decode('utf-8')\n",
    "    return image_base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6l0bCBkUA48"
   },
   "source": [
    "# Application:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhhL0cDBaN8O"
   },
   "source": [
    "Objectdetection: the application takes as input an image and returns the objects that have been detected on the image. It should also work for multiple images. Images are sent to the application via Post request as an array of base64 encoded Strings. Results should be returned as JSON Response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kmNbMDEglCh"
   },
   "source": [
    "# Version 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X4wSXQxLaFKY",
    "outputId": "b2c39d66-082a-4bb3-8250-e70feb2ce2b1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
    "#module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\"\n",
    "detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
    "\n",
    "def detection_loop(images):\n",
    "    bounding_boxes = []\n",
    "    inf_times = []\n",
    "    for image in images:\n",
    "        # decode image string:\n",
    "        image_tensor = image_base64_to_input_format(image)\n",
    "        #img = np.array(Image.open(io.BytesIO(base64.b64decode(image))))\n",
    "        #display_image(img)\n",
    "\n",
    "        #converted_img  = tf.image.convert_image_dtype(decoded_tensor, tf.float32)[tf.newaxis, ...]\n",
    "        start_time = time.time()\n",
    "        result = detector(image_tensor)\n",
    "        end_time = time.time()\n",
    "\n",
    "        #result = {key:value.numpy() for key,value in result.items()}\n",
    "        colors = np.array([[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]])\n",
    "        boxes = result[\"detection_boxes\"][0][:20]\n",
    "        print( boxes)\n",
    "        expanded =  np.expand_dims(boxes, axis=0)\n",
    "        res_image = tf.image.draw_bounding_boxes(image_tensor, expanded, colors)\n",
    "        #display_image()\n",
    "      \n",
    "        res_image = np.squeeze(res_image)\n",
    "        res_image = res_image.astype(np.uint8)\n",
    "# Display the image using Matplotlib\n",
    "        plt.imshow(res_image)\n",
    "        plt.axis('off')  # Turn off axis labels\n",
    "        plt.show()\n",
    "        # display_image = input_format_to_image_base64(res_image)\n",
    "        # display_image_from_base64(display_image)\n",
    "        # print(\"Found %d objects.\" % len(result[\"num_detections\"]))\n",
    "        # print(\"Inference time: \", end_time-start_time)\n",
    "        # print(result[\"detection_boxes\"],)\n",
    "\n",
    "        bounding_boxes.append(result[\"detection_boxes\"])\n",
    "        inf_times.append(end_time-start_time)\n",
    "        print(\"Done!\")\n",
    "\"\"\"\n",
    "        data = {\"status\": 200,\n",
    "              \"bounding_boxes\": bounding_boxes,\n",
    "              \"inf_time\": inf_times,\n",
    "              \"avg_inf_time\": str(np.mean(inf_times)),\n",
    "              \"upload_time\": [],\n",
    "              \"avg_upload_time\": \"\"}\n",
    "\"\"\"\n",
    "    #return make_response(jsonify(data), 200)\n",
    "    #return(data)\n",
    "\n",
    "\n",
    "result = detection_loop(images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XZ1GI0ENP3eJ",
    "outputId": "8c07a869-7393-4d2f-a571-f0ee3d07e57e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "result[\"inf_time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQ_k_My2Xwwe"
   },
   "source": [
    "# Version 2 (with load images):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnx5peFiP46i",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detection_loop(filename_image):\n",
    "  # input is a list of filenames to images\n",
    "\n",
    "  # load object detection module:\n",
    "  module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
    "  detector = hub.load(module_handle).signatures['default']\n",
    "\n",
    "  bounding_boxes = []\n",
    "  inf_times = []\n",
    "  upload_times = []\n",
    "  for filename in filename_image:\n",
    "\n",
    "    # load image:\n",
    "    start_time = time.time()\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    end_time = time.time()\n",
    "    upload_times.append(end_time-start_time)\n",
    "\n",
    "    # detect objects on image:\n",
    "    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "    start_time = time.time()\n",
    "    result = detector(converted_img)\n",
    "    end_time = time.time()\n",
    "\n",
    "    result = {key:value.numpy() for key,value in result.items()}\n",
    "\n",
    "    print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
    "    print(\"Inference time: \", end_time-start_time)\n",
    "\n",
    "    bounding_boxes.append(result[\"detection_boxes\"])\n",
    "    inf_times.append(end_time-start_time)\n",
    "  print(\"Detection Done!\")\n",
    "\n",
    "  data = {\"status\": 200,\n",
    "          \"bounding_boxes\": bounding_boxes,\n",
    "          \"inf_time\": inf_times,\n",
    "          \"avg_inf_time\": str(np.mean(inf_times)),\n",
    "          \"upload_time\": upload_times,\n",
    "          \"avg_upload_time\": str(np.mean(upload_times))}\n",
    "\n",
    "  return make_response(jsonify(data), 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
